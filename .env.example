# Example Environment Variables for llmdebate2

# --- LLM API Keys (Required) ---
# Replace with your actual keys
OPENAI_API_KEY="YOUR_OPENAI_API_KEY_GOES_HERE"
GEMINI_API_KEY="YOUR_GEMINI_API_KEY_GOES_HERE"
# GROK_API_KEY="YOUR_GROK_API_KEY_GOES_HERE" # If using Grok

# --- LLM Configuration (Optional) ---
# Default model key used by LLMInterface if not specified during instantiation
# Must match a key in config.json (e.g., "gpt-o4-mini")
DEFAULT_LLM_MODEL="gpt-o4-mini"

# --- V2 Configuration (Optional) ---
# Name of the agent to use for generating the initial prose baseline in V2
# Must match one of the client function keys (e.g., "O4-mini", "Gemini-2.5")
ANCHOR_AGENT_NAME="O4-mini"

# --- Web Interface Configuration (Optional) ---
# Maximum number of debate rounds in web UI (default: 3)
WEB_MAX_ROUNDS=3
# Number of top factors to merge in web UI (default: 5)
WEB_TOP_K=5
# Host and port for Flask web server
FLASK_RUN_HOST=127.0.0.1
FLASK_RUN_PORT=5000
# Enable Flask debug mode (True/False)
FLASK_DEBUG=False 